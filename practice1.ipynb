{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943c013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n",
      "tensor([2.], grad_fn=<MulBackward0>)\n",
      "tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 创建一个需要梯度的张量\n",
    "tensor_requires_grad = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "# 进行一些操作\n",
    "tensor_result = tensor_requires_grad * 2\n",
    "\n",
    "# 计算梯度\n",
    "tensor_result.backward()\n",
    "print(tensor_requires_grad.grad)  # 输出梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dce74377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.2693\n",
      "Epoch [20/100], Loss: 1.2239\n",
      "Epoch [30/100], Loss: 1.1802\n",
      "Epoch [40/100], Loss: 1.1382\n",
      "Epoch [50/100], Loss: 1.0981\n",
      "Epoch [60/100], Loss: 1.0598\n",
      "Epoch [70/100], Loss: 1.0232\n",
      "Epoch [80/100], Loss: 0.9883\n",
      "Epoch [90/100], Loss: 0.9551\n",
      "Epoch [100/100], Loss: 0.9234\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. 定义一个简单的神经网络模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)  # 输入层到隐藏层\n",
    "        self.fc2 = nn.Linear(2, 1)  # 隐藏层到输出层\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU 激活函数\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 2. 创建模型实例\n",
    "model = SimpleNN()\n",
    "\n",
    "# 3. 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 均方误差损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 优化器\n",
    "\n",
    "# 4. 假设我们有训练数据 X 和 Y\n",
    "X = torch.randn(10, 2)  # 10 个样本，2 个特征\n",
    "Y = torch.randn(10, 1)  # 10 个目标值\n",
    "\n",
    "# 5. 训练循环\n",
    "for epoch in range(100):  # 训练 100 轮\n",
    "    optimizer.zero_grad()  # 清空之前的梯度\n",
    "    output = model(X)  # 前向传播\n",
    "    loss = criterion(output, Y)  # 计算损失\n",
    "    loss.backward()  # 反向传播\n",
    "    optimizer.step()  # 更新参数\n",
    "    \n",
    "    # 每 10 轮输出一次损失\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee33c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 50, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda3\\envs\\P312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class STTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=6,\n",
    "        dim_feedforward=2048,\n",
    "        dropout=0.1,\n",
    "        max_seq_len=100,\n",
    "        max_gps_bins=1000,\n",
    "        multimodal_dim=256,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddings for time, GPS and multimodal inputs\n",
    "        self.time_embed = nn.Embedding(max_seq_len, d_model)\n",
    "        self.gps_embed  = nn.Embedding(max_gps_bins, d_model)\n",
    "        self.mm_proj    = nn.Linear(multimodal_dim, d_model)\n",
    "\n",
    "        # Positional encoding for sequence positions\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout, max_len=max_seq_len)\n",
    "\n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation=\"relu\"\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        # Final projection\n",
    "        self.output_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, time_seq, gps_seq, multimodal_feats):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            time_seq: LongTensor of shape (batch_size, seq_len) with time indices\n",
    "            gps_seq:  LongTensor of shape (batch_size, seq_len) with GPS-bin indices\n",
    "            multimodal_feats: FloatTensor of shape (batch_size, seq_len, multimodal_dim)\n",
    "        Returns:\n",
    "            embeddings: FloatTensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # embed each modality\n",
    "        t_emb = self.time_embed(time_seq)             # (B, L, D)\n",
    "        g_emb = self.gps_embed(gps_seq)               # (B, L, D)\n",
    "        mm_emb = self.mm_proj(multimodal_feats)       # (B, L, D)\n",
    "\n",
    "        # sum embeddings\n",
    "        x = t_emb + g_emb + mm_emb                    # (B, L, D)\n",
    "        x = self.pos_encoder(x)                       # add positional encoding\n",
    "\n",
    "        # transformer expects (L, B, D)\n",
    "        x = x.transpose(0, 1)                         # (L, B, D)\n",
    "        x = self.transformer_encoder(x)               # (L, B, D)\n",
    "        x = x.transpose(0, 1)                         # (B, L, D)\n",
    "\n",
    "        # final projection\n",
    "        out = self.output_proj(x)                     # (B, L, D)\n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # create positional encoding matrix once\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model)\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # shape (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: FloatTensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 4\n",
    "    seq_len = 50\n",
    "    multimodal_dim = 256\n",
    "\n",
    "    # Dummy inputs\n",
    "    time_seq = torch.randint(0, seq_len, (batch_size, seq_len))\n",
    "    gps_seq  = torch.randint(0, 1000, (batch_size, seq_len))\n",
    "    mm_feats = torch.randn(batch_size, seq_len, multimodal_dim)\n",
    "\n",
    "    model = STTransformer(\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=4,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.1,\n",
    "        max_seq_len=seq_len,\n",
    "        max_gps_bins=1000,\n",
    "        multimodal_dim=multimodal_dim,\n",
    "    )\n",
    "    outputs = model(time_seq, gps_seq, mm_feats)  # (batch_size, seq_len, d_model)\n",
    "    print(\"Output shape:\", outputs.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
